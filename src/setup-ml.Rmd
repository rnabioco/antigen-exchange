
```{r "h2o setup", include = FALSE}
# Default chunk options
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  echo    = FALSE,
  dpi     = 300
)

# Colors
pred_clrs <- c(
  `Ag-low`       = "#6A51A3",
  `Ag-competent` = "#E69F00",
  `Ag-high`      = "#D7301F"
)

# RF parameters
rf_dat_clmn  <- "Ag_class_ml"
rf_cell_type <- "cLEC"
rf_mouse     <- "d14"
ml_tm        <- str_remove(rf_mouse, "^d")
rf_typs      <- c("cLEC", "fLEC", "Collecting")

ag_lvls <- c("high", "low")

# Check for RF predictions
TRAIN_MODELS <- !file.exists(here(params$mod_dir, "ag-high_preds.qs"))

# Start h2o session
library(h2o)
library(parallel)

ncpus <- detectCores(logical = TRUE)

invisible(h2o.init(nthreads = ncpus - 2))
```

```{r "h2o functions"}
# Filter RF data to include correct cell types, timepoints, and to remove cells
# that were used to train models 
.filter_rf_data <- function(df, filt, timepoints = rf_tms, cell_types = rf_typs) {
  df %>%
    filter(
      tm %in% timepoints,
      subtype %in% cell_types,
      !training_data,
      {{filt}}
    )
}

.subset_rf_data <- function(so, filt, timepoints = rf_tms, cell_types = rf_typs) {
  cells <- so@meta.data %>%
    .filter_rf_data({{filt}}, timepoints, cell_types) %>%
    rownames()
  
  so %>%
    subset(cells = cells)
}

.prepare_ml_data <- function(obj, feats, class_clmn = rf_dat_clmn, scale = TRUE,
                             lvls = rev(ag_lvls), missing_value = NA) {
  # Identify missing features
  feats <- unique(feats)
  
  missing_feats <- feats[!feats %in% rownames(obj)]
  
  # Pull features
  dat <- obj %>%
    FetchData(unique(c(class_clmn, feats)))
  
  if (!is.null(class_clmn) && !is.null(lvls)) {
    dat <- dat %>%
      mutate(!!sym(class_clmn) := factor(!!sym(class_clmn), lvls))
  }
  
  dat[, missing_feats] <- as.numeric(missing_value)
  
  dat <- dat %>%  
    as_tibble(rownames = ".cell_id") %>%
    pivot_longer(all_of(feats))
  
  # Per-feature scaling
  if (scale) {
    dat <- dat %>%
      group_by(name) %>%
      mutate(value = as.numeric(scale(value))) %>%
      ungroup()
  }
  
  # Format final data.frame
  dat <- dat %>%
    pivot_wider() %>%
    column_to_rownames(".cell_id")
  
  dat
}

.predict_ml <- function(dat, predict_fn, features = ML_FEATS,
                        lvls = ag_lvls, class_clmn = rf_dat_clmn) {
  dat <- dat %>%
    .prepare_ml_data(
      feats      = features,
      class_clmn = class_clmn
    )
  
  pred <- predict_fn(as.h2o(dat)) %>%
    pull(adj_pred) %>%
    factor(lvls)
  
  res <- dat %>%
    select(any_of(class_clmn)) %>%
    mutate(pred = pred)
  
  res
}

#' Train models using h2o.automl()
#' 
#' @param ml_dat Named list containing H2OFrames for training ("train") and
#' validating ("valid") models
#' @param class_clmn Column in data containing binary classes to use for
#' classification
#' @param ml_dir Directory to use for saving models
.train_mls <- function(ml_dat, class_clmn = rf_dat_clmn, ml_dir = NULL, ...) {
  
  args <- list(
    y                  = class_clmn,
    training_frame     = ml_dat$train,
    leaderboard_frame  = ml_dat$valid,
    ...
  )
  
  args$nfolds          <- args$nfolds          %||% 10
  args$max_models      <- args$max_models      %||% 50
  args$seed            <- args$seed            %||% 42
  args$sort_metric     <- args$sort_metric     %||% "logloss"
  args$stopping_metric <- args$stopping_metric %||% "logloss"
  args$balance_classes <- args$balance_classes %||% TRUE
  args$keep_cross_validation_predictions <- args$keep_cross_validation_predictions %||% TRUE
  
  # Train models
  # * 10-fold cross-validation
  # * sort models based on logloss
  # * balance classes
  ml <- purrr::lift_dl(h2o.automl)(args)
  
  # Save models
  lb <- ml@leaderboard
  
  if (!is.null(ml_dir)) {
    pth <- path.expand(ml_dir)
    
    lb["model_id"] %>%
      as.vector() %>%
      walk(~ {
        .x %>%
          h2o.getModel() %>%
          h2o.saveModel(pth)
      })
  }
  
  # Calculate metrics for leaderboard
  # * return metrics for training and validation data
  # * use validation for setting classification cutoff
  lb_df <- lb %>%
    as_tibble() %>%
    select(-any_of("logloss"))  # this is calculated by .assess_ml()
  
  lb <- lb["model_id"] %>%
    as.vector() %>%
    map_dfr(~ {
      m <- .load_ml(ml_dir, .x)
      
      c("train", "valid", "test") %>%
        keep(~ .x %in% names(ml_dat)) %>%
        map_dfr(~ {
          m %>%
            .assess_ml(
              valid_data = ml_dat$valid %||% ml_dat$train,  # used to set classification cutoff
              test_data  = ml_dat[[.x]],                    # used to calculate accuracy metrics
              class_clmn = class_clmn
            ) %>%
            mutate(data = .x)
        })
    }) %>%
    left_join(lb_df, by = "model_id")
    
  # Format final output
  res <- list(
    model       = list(ml),
    leaderboard = lb
  )
  
  res
}

# Performs final performance assessment using test data
# * also identifies optimal classification cutoff based on validation data
# * returns data frame with final model and metrics
# * class levels and positive class are set during model training,
#   the first class is the negative class
# * Ag-high is set as the negative class for model training and when selecting
#   the classfication threshold
# * the returned F1 score uses Ag-high as the positive class
.assess_ml <- function(ml, metric = "f1", valid_data, test_data,
                       class_clmn = rf_dat_clmn) {
  
  # Identify optimal classification threshold using validation data
  perf <- ml %>%
    h2o.performance(newdata = valid_data) %>%
    h2o.metric() %>%
    as_tibble() %>%
    arrange(desc(!!sym(metric)), desc(specificity))
  
  threshold <- perf %>%
    head(1) %>%
    pull(threshold)
  
  # Perform final test using optimized threshold
  # * the last output column from h2o.predict is the positive class
  # * but confusionMatrix() uses the first level as the positive class
  predict_fn <- function(dat) {
    p <- h2o.predict(ml, dat) %>%
      as.data.frame()
    
    lvls <- colnames(p)[-1]
    pos  <- lvls[2]
    neg  <- lvls[1]
    
    p %>%
      mutate(
        adj_pred = if_else(!!sym(pos) > threshold, pos, neg),
        adj_pred = factor(adj_pred, lvls)
      )
  }
  
  pred <- test_data %>%
    predict_fn() %>%
    pull(adj_pred)
  
  class_lvls <- levels(pred)
  
  final_stats <- pred %>%
    confusionMatrix(
      reference = factor(as.vector(test_data[[class_clmn]]), class_lvls),
      positive  = class_lvls[1]
    )
  
  # Calculate logloss
  ll <- ml %>%
    h2o.performance(newdata = test_data)
  
  ll <- ll@metrics$logloss
  
  # Function to predict using optimized threshold
  # Format output tibble
  res <- final_stats$byClass %>%
    t() %>%
    as_tibble() %>%
    mutate(
      model_id   = ml@model_id,
      algorithm  = ml@algorithm,
      model      = list(ml),
      predict_fn = list(predict_fn),
      .before    = 1
    ) %>%
    mutate(
      logloss = ll,
      F1_neg = 2 * (
        (`Neg Pred Value` * Specificity) /
          (`Neg Pred Value` + Specificity)
      )
    )

  res
}

# Pulls the top models from an H2OAutoML object
.select_best_models <- function(lb, n = 2, model_path, metric = "logloss",
                                desc = FALSE) {
  
  sort_fn <- function(df) arrange(df, !!sym(metric))
  
  if (desc) sort_fn <- function(df) arrange(df, desc(!!sym(metric)))
  
  top_mls <- lb %>%
    as_tibble() %>%
    sort_fn() %>%
    pull(model_id) %>%
    head(n)
  
  res <- top_mls %>%
    set_names() %>%
    map(~ .load_ml(model_path, .x))
  
  res
}

.load_ml <- function(ml_dir, ml_id) {
  file.path(ml_dir, ml_id) %>%
    path.expand() %>%
    h2o.loadModel()
}
```

```{r "h2o Ag class", eval = TRAIN_MODELS}
# Set Ag-low/high classes for classifier
# * split for each cell type from each mouse
# * set subtype cutoff for all mice using d14 cutoff
# * for d14, Ag_score_3 and Ag_score_6 columns are identical to Ag_score
ag_clmns <- set_names(
  c("Ag_score", "Ag_score_3", "Ag_score_6"),
  c(rf_dat_clmn, "Ag_class_3wk", "Ag_class_6wk")
)

ag_clmns %>%
  iwalk(~ {
    ag_so <- lec_so %>%
      subset(mouse == rf_mouse) %>%
      cluster_signal(
        data_column  = .x,
        grp_column   = "subtype",
        clust_column = .y,
        method       = "km"
      )
    
    # The threshold will be the same for each column since this is set using
    # only the d14 mouse
    threshold <- ag_so@meta.data %>%
      filter(!!sym(.y) == "high") %>%
      group_by(subtype) %>%
      summarize(threshold = min(!!sym(.x)), .groups = "drop")
    
    threshold <- set_names(threshold$threshold, threshold$subtype)
    
    lec_so <<- lec_so %>%
      mutate_meta(
        mutate,
        !!sym(.y) := ifelse(
          !!sym(.x) >= threshold[as.character(subtype)],
          "high", "low"
        )
      )
  })

# Identify double-positive cells for the 6wk-3wk mouse
lec_so <- lec_so %>%
  mutate_meta(
    mutate,
    Ag_class_dual = case_when(
      mouse == "6wk-3wk" & (Ag_class_3wk == "high" & Ag_class_6wk == "high") ~ "double-high",
      mouse == "6wk-3wk" & (Ag_class_3wk == "high" | Ag_class_6wk == "high") ~ "single-high",
      mouse == "6wk"     & Ag_class_6wk == "high"                            ~ "6wk-high",
      mouse == "3wk"     & Ag_class_3wk == "high"                            ~ "3wk-high",
      TRUE                                                                   ~ "low"
    )
  )

# Save LEC object with Ag classifications
lec_so %>%
  qsave(here(params$so_dir, "lec_so.qs"))
```

```{r "h2o data splits", eval = TRAIN_MODELS}
# Split cells into train, validate, test
# * caret::createDataPartition() will maintain the class ratio for splits
data_splits <- list(
  train = 0.5,
  valid = 0.2,
  test  = 0.3
)

prop_train_valid <- data_splits$train + data_splits$valid

data_splits <- rf_typs %>%
  set_names() %>%
  map(~ {
    dat <- lec_so@meta.data %>%
      filter(mouse == rf_mouse, subtype == .x)
      
    cells    <- rownames(dat)
    outcomes <- pull(dat, rf_dat_clmn)
    
    set.seed(42)
    
    train_idx <- outcomes %>%
      createDataPartition(p = prop_train_valid) %>%
      unlist(use.names = FALSE)
    
    valid_idx <- outcomes[train_idx] %>%
      createDataPartition(p = data_splits$valid / prop_train_valid) %>%
      unlist(use.names = FALSE)
    
    # Set training cells
    train_cells <- cells[train_idx]
    
    if (!is_empty(valid_idx)) train_cells <- train_cells[-valid_idx]
    
    # Create split
    splits <- list(train = train_cells)
    
    if (!is_empty(valid_idx)) splits$valid <- cells[train_idx][valid_idx]
    
    splits$test <- cells[!cells %in% unlist(splits)]
    
    splits
  })

# Include cells from the 21 and 42 day timepoints for feature selection
data_splits %>%
  iwalk(~ {
    dat <- lec_so@meta.data %>%
      filter(tm %in% c(21, 42), subtype == .y)

    cells <- dat %>%
      split(.$tm) %>%
      map(~ {
        cells    <- rownames(.x)
        outcomes <- pull(.x, rf_dat_clmn)

        set.seed(42)

        feat_idx <- outcomes %>%
          createDataPartition(p = 0.1) %>%
          unlist(use.names = FALSE)

        cells[feat_idx]
      }) %>%
      unlist(use.names = FALSE)
    
    data_splits[[.y]]$feature <<- cells
  })

# Save cell IDs
TRAINING_CELLS <- c("train", "valid", "feature") %>%
  map(~ map(data_splits, pluck, .x)) %>%
  unlist(use.names = FALSE)

data_splits %>%
  qsave(here(params$mod_dir, "data_splits.qs"))
```

```{r "h2o fLEC data splits", eval = TRAIN_MODELS}
# Split cells into train, validate, test
# * caret::createDataPartition() will maintain the class ratio for splits
new_splits <- list(
  train = 0.7,
  valid = 0.15,
  test  = 0.15
)

prop_train_valid <- new_splits$train + new_splits$valid

new_splits <- set_names("fLEC") %>%
  map(~ {
    dat <- lec_so@meta.data %>%
      filter(mouse == rf_mouse, subtype == .x)
      
    cells    <- rownames(dat)
    outcomes <- pull(dat, rf_dat_clmn)
    
    set.seed(42)
    
    train_idx <- outcomes %>%
      createDataPartition(p = prop_train_valid) %>%
      unlist(use.names = FALSE)
    
    valid_idx <- outcomes[train_idx] %>%
      createDataPartition(p = new_splits$valid / prop_train_valid) %>%
      unlist(use.names = FALSE)
    
    # Set training cells
    train_cells <- cells[train_idx]
    
    if (!is_empty(valid_idx)) train_cells <- train_cells[-valid_idx]
    
    # Create split
    splits <- list(train = train_cells)
    
    if (!is_empty(valid_idx)) splits$valid <- cells[train_idx][valid_idx]
    
    splits$test <- cells[!cells %in% unlist(splits)]
    
    splits
  })

# Include cells from the 21 and 42 day timepoints for feature selection
new_splits %>%
  iwalk(~ {
    dat <- lec_so@meta.data %>%
      filter(tm %in% c(21, 42), subtype == .y)

    cells <- dat %>%
      split(.$tm) %>%
      map(~ {
        cells    <- rownames(.x)
        outcomes <- pull(.x, rf_dat_clmn)

        set.seed(42)

        feat_idx <- outcomes %>%
          createDataPartition(p = 0.1) %>%
          unlist(use.names = FALSE)

        cells[feat_idx]
      }) %>%
      unlist(use.names = FALSE)

    new_splits[[.y]]$feature <<- cells
  })

# Update data_splits
new_splits %>%
  iwalk(~ {
    data_splits[[.y]] <<- .x
  })

# Save cell IDs
TRAINING_CELLS <- c("train", "valid", "feature") %>%
  map(~ map(data_splits, pluck, .x)) %>%
  unlist(use.names = FALSE)

data_splits %>%
  qsave(here(params$mod_dir, "data_splits.qs"))
```

```{r "h2o feature selection 1", eval = TRAIN_MODELS}
# Identify top features to use for model training

# Filter for cells to use for feature selection
deg_so <- lec_so %>%
  subset(cells = TRAINING_CELLS)

# Identify Ag markers for each subtype separately
.identify_degs <- function(obj, var = NULL, group_clmn = rf_dat_clmn) {
  
  multi_var <- length(var) > 1
  
  if (multi_var) {
    obj <- obj %>%
      mutate_meta(~ {
        .x %>%
          rowwise() %>%
          mutate(var = str_c(!!!syms(var), sep = "-")) %>%
          ungroup()
      })
    
    orig_clmns <- var
    var <- "var"
  }
  
  res <- list(obj)
  
  if (!is.null(var)) {
    res <- obj %>%
      SplitObject(var)
  }
  
  res <- res %>%
    imap_dfr(~ {
      res <- .x %>%
        wilcoxauc(group_by = group_clmn)
      
      if (nrow(res) == 0) return(NULL)
      
      res %>%
        as_tibble() %>%
        filter(logFC > 0) %>%
        arrange(padj, pval, desc(logFC))
    }, .id = var)
  
  if (multi_var) {
    res <- res %>%
      separate_wider_delim(var, delim = "-", names = orig_clmns)
  }
  
  res
}

degs_1 <- deg_so %>%
  .identify_degs() %>%
  mutate(subtype = "all", tm = "all")

degs_2 <- deg_so %>%
  .identify_degs("subtype") %>%
  mutate(tm = "all")

degs_3 <- deg_so %>%
  .identify_degs("tm") %>%
  mutate(subtype = "all")

degs_4 <- deg_so %>%
  .identify_degs(c("subtype", "tm"))

# Filter based on differential expression
# * exclude ribosomal protein genes
# * use less stringent filtering to include more genes for training
# * exclude genes that are lowly expressed <20% of cells
exclude_feats <- c("Malat1", "Xist")

fc <- log(1)

degs <- bind_rows(degs_1, degs_2, degs_3, degs_4) %>%
  filter(
    logFC > fc,
    (pct_in > 20 | pct_out > 20),
    
    !grepl("^(mt-|R[pls])", feature),
    !feature %in% exclude_feats
  ) %>%
  arrange(pval)

# Save features
degs %>%
  write_tsv(here(params$mod_dir, "ag-high_degs.tsv.gz"))
```

```{r "h2o feature selection 2", eval = TRAIN_MODELS}
# Save features
# * assign features to Ag-low/high modules
ml_degs <- rf_typs %>%
  map_dfr(~ {
    degs %>%
      filter(subtype %in% c(.x, "all")) %>%
      mutate(
        key = case_when(
          subtype == .x & as.character(tm) == ml_tm    ~ 1,
          subtype == .x                                ~ 2,
          subtype == "all" & as.character(tm) == ml_tm ~ 3,
          as.character(tm) == ml_tm                    ~ 4,
          TRUE                                         ~ 5
        )
      ) %>%
      group_by(feature) %>%
      filter(key == min(key)) %>%
      ungroup() %>%
      mutate(list = .x)
  })

# Select equal number of top genes from Ag-low/high groups for each subtype
ml_degs <- ml_degs %>%
  filter(tm != "all", subtype == list) %>%
  arrange(padj, pval, desc(logFC)) %>%
  group_by(list, tm, group) %>%
  slice(1:100) %>%
  ungroup()

ml_degs %>%
  write_tsv(here(params$mod_dir, "ag-high_features.tsv.gz"))

# All features
ml_feats <- ml_degs %>%
  split(.$list) %>%
  map(~ unique(.x$feature))

ML_FEATS <- unique(unlist(ml_feats))
```

```{r "h2o training data", eval = TRAIN_MODELS}
# Create data.frames
# * separate frame for each subtype and train/validate/test split
# * expression values are scaled separately for each gene for each subset/split
ml_data <- data_splits %>%
  map(~ .x[!names(.x) == "feature"]) %>%
  imap(~ {
    cells <- .x
    typ   <- .y
    
    fts <- ml_feats[[typ]]
    
    cells %>%
      map(~ {
        dat <- lec_so %>%
          subset(cells = .x) %>%
          subset(subtype == typ) %>%
          .prepare_ml_data(feats = fts) %>%
          as.h2o()
        
        # the first level should be the negative class
        # * want to train using Ag-low as the positive class since it is the
        #   minority class
        dat[[rf_dat_clmn]] <- dat[[rf_dat_clmn]] %>%
          h2o.setLevels(ag_lvls, in.place = TRUE)
        
        dat
      })
  })
```

```{r "h2o train models", eval = TRAIN_MODELS}
# Train models
# * set Ag-low as the positive class, since there are fewer Ag-low cells
# * scale expression separately for training/validation/testing data
lb <- c(42, 43) %>%
  map_dfr(~ {
    seed <- .x
    
    rf_typs %>%
      set_names() %>%
      map_dfr(~ {
        typ    <- .x
        cells  <- data_splits[[typ]]
        fts    <- ml_feats[[typ]]    
        ml_dat <- ml_data[[typ]]
        
        res <- ml_dat %>%
          .train_mls(
            class_clmn = rf_dat_clmn,
            ml_dir     = here(params$mod_dir, typ),
            max_models = 100,
            seed       = seed
          ) %>%
          .$leaderboard %>%
          mutate(
            features   = list(fts),
            train_data = list(cells$train),
            valid_data = list(cells$valid),
            test_data  = list(cells$test)
          ) %>%
          mutate(
            subtype = typ,
            seed    = seed,
            .before = 1
          )
        
        res
      })
  })

lb %>%
  qsave(here(params$mod_dir, "ag-high_all_models.qs"))

lb %>%
  select(-where(is.list)) %>%
  write_tsv(here(params$mod_dir, "ag-high_leaderboard.tsv.gz"))
```

```{r "h2o final test", eval = TRAIN_MODELS}
# Select best models
BEST_MLS <- lb %>%
  filter(
    data == "valid",
    algorithm %in% c("gbm", "deeplearning")
  ) %>%
  group_by(algorithm, subtype) %>%
  slice_max(F1, n = 10) %>%
  slice_max(Specificity, n = 1) %>%
  slice_max(`Balanced Accuracy`, n = 1) %>%
  slice_min(logloss, n = 1) %>%

  group_by(subtype) %>%
  arrange(desc(F1), desc(Specificity), desc(`Balanced Accuracy`), logloss) %>%
  mutate(training_rank = row_number()) %>%
  ungroup() %>%
  
  pmap_dfr(~ {
    args <- list(...)
    typ  <- args$subtype
    dat  <- ml_data[[typ]]
    
    ml <- .load_ml(
      here(params$mod_dir, typ),
      args$model_id
    )
      
    res <- ml %>%
      .assess_ml(
        valid_data = dat$valid,
        test_data  = dat$test
      ) %>%
      mutate(
        train_data = list(dat$train),
        valid_data = list(dat$valid),
        test_data  = list(dat$test)
      ) %>%
      mutate(
        subtype       = typ,
        seed          = args$seed,
        training_rank = args$training_rank,
        .before = 1
      )
    
    res
  })

BEST_MLS <- BEST_MLS %>%
  mutate(algorithm = fct_relevel(algorithm, c("gbm", "deeplearning"))) %>%
  arrange(subtype, algorithm) %>%
  group_by(subtype) %>%
  mutate(model_name = row_number(), .before = training_rank) %>%
  ungroup()

# Save models
BEST_MLS %>%
  qsave(here(params$mod_dir, "ag-high_best_models.qs"))
```

```{r "h2o Ag module features", eval = TRAIN_MODELS}
# Filter for top features
# * include features based on cumulative feature importance
# * keep top features that account for 99% of overall importance
MODULE_FEATS <- BEST_MLS %>%
  split(.$model_name) %>%
  map(~ {
    .x %>%
      pull(model, subtype) %>%
      imap(~ {
        imprts <- .x@model$variable_importances %>%
          as_tibble()
        
        imprts <- imprts %>%
          filter(cumsum(percentage) <= 0.99)  # remove any features not used by
                                              # model
        imprts$variable
      })
  })

# Assign Ag-low/high class
# * assign genes as Ag-low/high based on which group they are more highly
#   expressed in for the subtype used for training
MODULE_FEATS <- MODULE_FEATS %>%
  map(~ {
    .x %>%
      imap(~ {
        fts <- .x
        typ <- .y
        
        res <- ml_degs %>%
          filter(list == typ, feature %in% fts) %>%
          group_by(feature) %>%
          filter(key == min(key)) %>%
          slice_min(padj) %>%
          slice_min(pval) %>%
          slice_max(logFC) %>%
          ungroup()
          
        res %>%
          split(.$group) %>%
          map(~ {
            gns <- unique(.x$feature)
            
            fts[fts %in% gns]  # keep previous feature ordering
          })
      })
  })

# Save top features
MODULE_FEATS %>%
  qsave(here(params$mod_dir, "ag-high_module_features.qs"))
```

```{r "h2o predict Ag class", eval = TRAIN_MODELS}
# Predict Ag class
# * THIS RETURNS WARNINGS
# * Test/Validation dataset is missing column 'Orai10': substituting in a column of NaN
# * suggests there are genes used for training that are not present in data
#   for predictions
lec_so <- lec_so %>%
  mutate_meta(
    mutate,
    training_data = .cell_id %in% TRAINING_CELLS
  )
 
ML_PREDS <- BEST_MLS %>%
  split(.$model_name) %>%
  map(~ {
    .x %>%
      pmap_dfr(~ {
        args <- list(...)
        
        dat <- lec_so@meta.data %>%
          filter(!training_data, subtype == args$subtype) %>%
          split(.$mouse) %>%
          map(~ subset(lec_so, cells = rownames(.x)))
        
        res <- dat %>%
          map_dfr(
            .predict_ml,
            predict_fn = args$predict_fn,
          )
        
        res
      })
  })

# Write table with predictions
ML_PREDS %>%
  qsave(here(params$mod_dir, "ag-high_preds.qs"))
```

```{r "h2o load models"}
# Load models
# lb <- qread(here(params$mod_dir, "ag-high_all_models.qs"))
lb       <- read_tsv(here(params$mod_dir, "ag-high_leaderboard.tsv.gz"))
BEST_MLS <- qread(here(params$mod_dir, "ag-high_best_models.qs"))

BEST_MLS$model <- BEST_MLS %>%
  pull(model_id, subtype) %>%
  imap(~ {
    here(params$mod_dir, .y, .x) %>%
      path.expand() %>%
      h2o.loadModel()
  })

# Load data splits used for training models
data_splits <- qread(here(params$mod_dir, "data_splits.qs"))

TRAINING_CELLS <- c("train", "valid", "feature") %>%
  map(~ map(data_splits, pluck, .x)) %>%
  unlist(use.names = FALSE)

# Differentially expressed genes
ml_degs <- read_tsv(here(params$mod_dir, "ag-high_features.tsv.gz"))
degs    <- read_tsv(here(params$mod_dir, "ag-high_degs.tsv.gz"))

ml_feats <- ml_degs %>%
  split(.$list) %>%
  map(~ unique(.x$feature))

# RF features
ML_FEATS <- read_tsv(here(params$mod_dir, "ag-high_features.tsv.gz"))
ML_FEATS <- unique(ML_FEATS$feature)

MODULE_FEATS <- qread(here(params$mod_dir, "ag-high_module_features.qs"))

# Predictions
ML_PREDS <- qread(here(params$mod_dir, "ag-high_preds.qs"))

# Set module names
MODULE_NAMES <- MODULE_FEATS[[1]][rf_typs] %>%
  imap(~ {
    typ <- .y
    
    imap_chr(.x, ~ str_c(typ, "_", .y))
  }) %>%
  unlist(use.names = FALSE)

module_labels <- MODULE_NAMES %>%
  str_replace("_(?=high|low)", " Ag-") %>%
  str_c(" module")

MODULE_NAMES_2 <- set_names(MODULE_NAMES, module_labels)
MODULE_NAMES   <- set_names(module_labels, MODULE_NAMES)
```
